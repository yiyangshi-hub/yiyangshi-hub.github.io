[
  {
    "objectID": "posts/textmining/index.html",
    "href": "posts/textmining/index.html",
    "title": "Text Mining Learning Guide",
    "section": "",
    "text": "tidy text analysis (why do we want to do this?)\nthe package (gutenbergr and what is it)\ndifferent lexicons\nsentiment analysis\nreminder about joins"
  },
  {
    "objectID": "posts/textmining/index.html#resources",
    "href": "posts/textmining/index.html#resources",
    "title": "Text Mining Learning Guide",
    "section": "Resources",
    "text": "Resources\n[Textbook on tidy text]https://www.tidytextmining.com/index.html\n[Sentiment Analysis and Tidy Tuesday]https://juliasilge.com/blog/animal-crossing/"
  },
  {
    "objectID": "posts/textmining/index.html#the-tidy-text-format-document-term-matrixdtm",
    "href": "posts/textmining/index.html#the-tidy-text-format-document-term-matrixdtm",
    "title": "Text Mining Learning Guide",
    "section": "The tidy text format & Document-Term Matrix(DTM)",
    "text": "The tidy text format & Document-Term Matrix(DTM)\n\nAccording to the “Text Mining with R” textbook, the tidy text format is a table with one-token-per-row. This means that:\n\nEach variable is a column\nEach observation is a row\nEach type of observation unit is a table Therefore, a token is a meaningful unit of text, like a word, that we as data scientists are interested in analyzing. For tidy text mining, we may want to do a process called tokenization which splits words into tokens and then allows us to normally analyze by word.\n\nIn chapter 5 of “Text Mining with R”, DTM is one of the most common structure that text mining work with, where\n\nEach row represents a document (book or article)\nEach column represents one term.\nEach value (typically) contains the number of appearances of that term in that document.\n\n\nSince DTM objects and and tidy data frames are two incompactible objects, we cannot use tidy tools to analyze a DTM object. Tidytext package provides two functions that convert between these two formats:\n\ntidy() turns a DTM to a tidy dataframe.\ncast() turns a tidy one term per row dataframe to a matrix.\n\n\n# DTM\n# Install the package AssociatedPress before you run this code chunk\ndata(\"AssociatedPress\", package = \"topicmodels\")\n\n# tidying a DTM\nap_td <- tidy(AssociatedPress)\nap_td\n\n# A tibble: 302,031 × 3\n   document term       count\n      <int> <chr>      <dbl>\n 1        1 adding         1\n 2        1 adult          2\n 3        1 ago            1\n 4        1 alcohol        1\n 5        1 allegedly      1\n 6        1 allen          1\n 7        1 apparently     2\n 8        1 appeared       1\n 9        1 arrested       1\n10        1 assault        1\n# … with 302,021 more rows\n\n# joining tidy dataframe with sentiments dataframe\nap_sentiments <- ap_td %>% \n  inner_join(get_sentiments(\"bing\"), by = c(term = \"word\"))\n\n# Here is an example from the \"Text Mining with R\"\nap_sentiments %>% \n  count(sentiment, term, wt = count) %>% \n  ungroup() %>% \n  filter(n > 200) %>% \n  mutate(m = ifelse(sentiment == \"positive\", n, -n)) %>% \n  mutate(term = reorder(term, m)) %>% \n  ggplot(aes(x = m, y = term, fill = sentiment)) +\n  geom_col() +\n  labs(x = \"Contribution to Sentiment\", y = \"\")\n\n\n\n\n\n# casting a tidy dataframe\nap_td %>% \n  cast_dtm(document, term, count)\n\n<<DocumentTermMatrix (documents: 2246, terms: 10473)>>\nNon-/sparse entries: 302031/23220327\nSparsity           : 99%\nMaximal term length: 18\nWeighting          : term frequency (tf)"
  },
  {
    "objectID": "posts/textmining/index.html#accessing-the-jane-austin-books",
    "href": "posts/textmining/index.html#accessing-the-jane-austin-books",
    "title": "Text Mining Learning Guide",
    "section": "Accessing the Jane Austin Books",
    "text": "Accessing the Jane Austin Books\n\noriginal_books <- austen_books() %>%\n  group_by(book) %>%\n  mutate(linenumber = row_number(),\n         chapter = cumsum(str_detect(text, \n                                     regex(\"^chapter [\\\\divxlc]\",\n                                           ignore_case = TRUE)))) %>%\n  ungroup()\n\noriginal_books\n\n# A tibble: 73,422 × 4\n   text                    book                linenumber chapter\n   <chr>                   <fct>                    <int>   <int>\n 1 \"SENSE AND SENSIBILITY\" Sense & Sensibility          1       0\n 2 \"\"                      Sense & Sensibility          2       0\n 3 \"by Jane Austen\"        Sense & Sensibility          3       0\n 4 \"\"                      Sense & Sensibility          4       0\n 5 \"(1811)\"                Sense & Sensibility          5       0\n 6 \"\"                      Sense & Sensibility          6       0\n 7 \"\"                      Sense & Sensibility          7       0\n 8 \"\"                      Sense & Sensibility          8       0\n 9 \"\"                      Sense & Sensibility          9       0\n10 \"CHAPTER 1\"             Sense & Sensibility         10       1\n# … with 73,412 more rows\n\n\nNow, to work with the tidy dataset we just created, we need to restructure it into a one-token-per-row format which leads us to our unnest_tokens function\n\ntidy_books <- original_books %>%\n  unnest_tokens(word, text)\n\nThe unnest_tokens uses the tokenizers package to separate each line of text in the original data frame into tokens. (More on different tyoes of tokenizing later)\nNow that our data is in a one-word-per-row format, we can use tidy tools (like dplyr)."
  },
  {
    "objectID": "posts/textmining/index.html#removing-words",
    "href": "posts/textmining/index.html#removing-words",
    "title": "Text Mining Learning Guide",
    "section": "Removing Words",
    "text": "Removing Words\nWe can use the tidytext dataset stop_words with an anti_join to remove common English words like “the”, “of”, and “to” which potentially not be fruitful in a sentiment analysis context.\n\ntidy_books <- tidy_books %>%\n  anti_join(stop_words)\n\nJoining, by = \"word\""
  },
  {
    "objectID": "posts/textmining/index.html#practice",
    "href": "posts/textmining/index.html#practice",
    "title": "Text Mining Learning Guide",
    "section": "Practice",
    "text": "Practice\n\nFind the most common words in all the tidy_books books as a whole. Create a visualization via ggplot to show the most common words in Jane Austen books.\n\n\ntidy_books\n\n# A tibble: 217,609 × 4\n   book                linenumber chapter word       \n   <fct>                    <int>   <int> <chr>      \n 1 Sense & Sensibility          1       0 sense      \n 2 Sense & Sensibility          1       0 sensibility\n 3 Sense & Sensibility          3       0 jane       \n 4 Sense & Sensibility          3       0 austen     \n 5 Sense & Sensibility          5       0 1811       \n 6 Sense & Sensibility         10       1 chapter    \n 7 Sense & Sensibility         10       1 1          \n 8 Sense & Sensibility         13       1 family     \n 9 Sense & Sensibility         13       1 dashwood   \n10 Sense & Sensibility         13       1 settled    \n# … with 217,599 more rows"
  },
  {
    "objectID": "posts/textmining/index.html#practice-1",
    "href": "posts/textmining/index.html#practice-1",
    "title": "Text Mining Learning Guide",
    "section": "Practice",
    "text": "Practice\n\nTo do: Pepare the gutenberg dataset for the Bronte sisters for sentiment analysis (hint: think unnest_tokens and anti_join). From there, how would we find the the most common words in the novels?\n\n\nbronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))\n\n## What would we insert in the in the parentheses?\nbronte %>%\n  unnest_tokens(???, ???) %>%\n  anti_join(????)\n\n## Now, use previous examples to find the most common words\n\nError: <text>:5:20: unexpected ','\n4: bronte %>%\n5:   unnest_tokens(???,\n                      ^"
  },
  {
    "objectID": "posts/textmining/index.html#section-practice",
    "href": "posts/textmining/index.html#section-practice",
    "title": "Text Mining Learning Guide",
    "section": "Section Practice",
    "text": "Section Practice\nSo, how do we think we can calculate the frequency of each word for the works of Jane Austin and the Bronte sisters? How would we graph this?\n\nfrequency <- bind_rows(mutate (bronte, author = \n\"Bronte Sister\"),\nmutate(tidy_books, author = \"Jane Austen\"))\n\nError in mutate(bronte, author = \"Bronte Sister\"): object 'bronte' not found\n\n ## Can you find a way to use a regx here?\n\nHow would we plot this (hint: use ggplot)?\n\n\n\nWe can also run correlation tests, which allows us to quantify how similar and different these sets of word frequencies are.\nLet’s run a Pearson’s correlation test between the Bronte sisters and Jane Austins’ works.\n\ncor.test(data = frequency[frequency$author == \"Brontë Sisters\",],\n         ~ proportion + `Jane Austen`)"
  },
  {
    "objectID": "posts/textmining/index.html#practice-2",
    "href": "posts/textmining/index.html#practice-2",
    "title": "Text Mining Learning Guide",
    "section": "Practice",
    "text": "Practice\nWhat does this information tell you?\n\n\n\n\nANSWER:\n\n\n\n\nSentiment Analysis with tidy data\nSo what is sentiment analysis? Sentiment Analysis allows us to analyze the emotion in text programmatically. one of the more common ways to do this is to consider the text as a combination of its individual words and the sentiment content of the whole text as the sum of the sentiment content of the individual words.\nHow are sentiment lexicons created and validated? They are constructed either via crowdsourcing or by an individual which they was validated using crowdsourcing, restaurant or movie reviews, or Twitter data.\nThere are a few different lexicon databases that can be used to do sentiment analysis (read more here <>) but for this we will use the nrc lexicon.\n\nget_sentiments(\"nrc\")\n\n# A tibble: 13,872 × 2\n   word        sentiment\n   <chr>       <chr>    \n 1 abacus      trust    \n 2 abandon     fear     \n 3 abandon     negative \n 4 abandon     sadness  \n 5 abandoned   anger    \n 6 abandoned   fear     \n 7 abandoned   negative \n 8 abandoned   sadness  \n 9 abandonment anger    \n10 abandonment fear     \n# … with 13,862 more rows\n\n\nNOTE: THIS WILL TAKE A WHILE TO DOWNLOAD\nThe nrc lexicon works by giving a list of English words and then giving their association to eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). The annotations for the lexicon is collected manually through crowd sourcing.\nTo explore more about the nrc lexicon: https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm#:~:text=The%20NRC%20Emotion%20Lexicon%20is,were%20manually%20done%20by%20crowdsourcing.\nAs shown below, once we add new variables and organize the book so each word has a distinct row, we want to use an inner_join to find the words in common in the book Emma with the “joy” words (or nrc_join dataset) in the nrc lexicon.\nLet’s try an example: What are the most common joy words in the book Emma?\n\ntidy_books <- austen_books() %>%\n  group_by(book) %>%\n  mutate(\n    linenumber = row_number(),\n    chapter = cumsum(str_detect(text, \n                                regex(\"^chapter [\\\\divxlc]\", \n                                      ignore_case = TRUE)))) %>%\n  ungroup() %>%\n  unnest_tokens(word, text)\n\nnrc_joy <- get_sentiments(\"nrc\") %>% \n  filter(sentiment == \"joy\")\n\ntidy_books %>%\n  filter(book == \"Emma\") %>%\n  inner_join(nrc_joy) %>%\n  count(word, sort = TRUE)\n\nJoining, by = \"word\"\n\n\n# A tibble: 301 × 2\n   word          n\n   <chr>     <int>\n 1 good        359\n 2 friend      166\n 3 hope        143\n 4 happy       125\n 5 love        117\n 6 deal         92\n 7 found        92\n 8 present      89\n 9 kind         82\n10 happiness    76\n# … with 291 more rows"
  },
  {
    "objectID": "projects/STAT 456/index.html",
    "href": "projects/STAT 456/index.html",
    "title": "The 2020 Presidential Election: A Sentiment Analysis of News Media Coverage on Joe Biden and Donald Trump",
    "section": "",
    "text": "This project aims to explore the connection between how the two main candidates in the 2020 U.S. presidential election, Joe Biden and Donald Trump were portrayed in the media via sentiment analysis. To do this, we used the AFINN lexicon to longitudinally explore trends over the span of 2 years, from 2020 to 2022 to see there were connections between specific events in the world or in the candidates lives and how the media portrayed the candidates. To explore this further, we picked a news source from within the United States, the New York Times and one from the U.K., the Guardian, to see if the trends differ domestically versus internationally.\nHere’s the link to the github repo"
  },
  {
    "objectID": "projects/STAT452/index.html",
    "href": "projects/STAT452/index.html",
    "title": "BikeShare DC Ridership Behavior",
    "section": "",
    "text": "The increasing popularity of bike sharing solves the last-mile problem for the commuters in cities by deploying bike sharing stations at bus stops, metro stations, and libraries. Increasing gas prices, maintenance costs, and traffic jams are obstacles for commuters that travel by car. Bike sharing services are a cost-effective and eco-friendly alternative.\nOur project discuss the influence and efficiency of the bike sharing system in DC by evaluating Capital Bikeshare stations’ popularity with a longitudinal approach in 2021. We utilized a generalized estimating equation (GEE) to model the average daily rides per station by incorporating weather information, demographic characteristics, and spatial elements under the assumption of an exchangeable working correlation structure.\nWe conclude that the temperature and distance to the Washington Monument are negatively correlated. At the same time, low humidity, low wind speeds, and the proportion of White residents per census tract are positively correlated with the number of daily riders."
  },
  {
    "objectID": "projects/STAT453/index.html",
    "href": "projects/STAT453/index.html",
    "title": "Random Survival Forest with an Application to Employee Attrition",
    "section": "",
    "text": "In this project, we intended to predict the number of years an employee could work in IBM with random survival forest incorporated. Specifically, we analyzed the underlying factors that could contribute to our prediction on the number of years an employee could work at IBM. Since there are many categorical variables in the data set, we believe Random Survival Forest is a fittest model for analysis. Also, we compared the performance of our Random Survival Forest with AFT models and Cox PH models."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nThe 2020 Presidential Election: A Sentiment Analysis of News Media Coverage on Joe Biden and Donald Trump\n\n\n\nText Mining\n\n\nSentiment Analysis\n\n\nWeb Scraping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Survival Forest with an Application to Employee Attrition\n\n\n\nResearch\n\n\nSurvival Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHotel Cancellation Prediction\n\n\n\nResearch\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBikeShare DC Ridership Behavior\n\n\n\nResearch\n\n\nCorrelated Data\n\n\n\nA project investigating Capital Bikeshare\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yiyang Shi",
    "section": "",
    "text": "he/him/his\nGraduate Student at the University of Michigan Ann Harbor\nM.S. in Industrial and Operation Engineering | Aug 2023 - May 2025\n\n\n\nData Centers Intern Jul 2022 - Dec 2022 | Convergint\nTeaching Assistant of Stat Machine Learning Jan 2022 - May 2022 | Macalester College\nDatabases Intern May 2021 - Aug 2021 | International Institute of Minnesota\nTeaching Assistant of Intro to Data Science Jan 2021 - May 2021 | Macalester College\n\n\n\nMacalester College | St. Paul MN\nB.A. in Applied Math & Statistics | Sep 2019 - May 2023"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nThe 2020 Presidential Election\n\n\n\n\n\n\n\nR\n\n\nText Mining\n\n\nSentiment Analysis\n\n\n\n\nA Sentiment Analysis of News Media Coverage on Joe Biden and Donald Trump\n\n\n\n\n\n\nMar 1, 2023\n\n\nYiyang Shi, Cecelia Kaufmann, Tam Nguyen\n\n\n\n\n\n\n  \n\n\n\n\nText Mining Learning Guide\n\n\n\n\n\n\n\nR\n\n\nText Mining\n\n\nSentiment Analysis\n\n\n\n\nA learning guide of text mining with the dataset in RStudio\n\n\n\n\n\n\nMar 1, 2023\n\n\nYiyang Shi, Cecelia Kaufmann, Tam Nguyen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Sentiment Analysis/index.html",
    "href": "posts/Sentiment Analysis/index.html",
    "title": "The 2020 Presidential Election",
    "section": "",
    "text": "Our project aims to explore the connection between how the two main candidates in the 2020 U.S. presidential election, Joe Biden and Donald Trump were portrayed in the media via sentiment analysis. To do this, we used the AFINN lexicon to longitudinally explore trends over the span of 2 years, from 2020 to 2022 to see there were connections between specific events in the world or in the candidates lives and how the media portrayed the candidates. To explore this further, we picked a news source from within the United States, the New York Times and one from the U.K., the Guardian, to see if the trends differ domestically versus internationally.\n\n\n\nHow do the sentiments between Donald Trump and Joe Biden vary between New York Times and Guardian articles before and after the 2020 U.S. Presidential election?\nHow many NYT articles about Trump/Biden are positive/negative? How many positive and negative articles for Trump/Biden for The Guardian? Is there a difference in the article percentages between the New York Times and the Guardian?\nCan we correlate sentiments to significant events for both candidates?\n\n\n\nWe decided to use sentiment analysis to approach our analysis of the articles and article text. Through our discussions, we found that sentiment analysis will help to gain a deeper understanding of how newspapers portray the two leading candidates for the U.S. 2020 election and how that changed over the span of two years. Before we can get into our data collection process and analysis of articles, it is important we define key terms and packages that we used to be able to analyze our data in a concise manner.\n\n\n\nSentiment analysis, which is also sometimes referred to as opinion mining is a way to use natural language processing (NLP) to identify the emotional tone behind a body of text. Through different types of lexicons, a word or string of words can be identified as positive, negative, or neutral.\n\n\n\nFor lexicon-based sentiment analysis, which we used for this research, words in the text are labeled as positive or negative with the help of a valence dictionary. For this research, we used the AFINN lexicon, which assigns words with a score between -5 and 5, with a more negative score indicating a more negative word and vice versa. We felt for this research that a weighted lexicon dictionary would make the most sense, especially since we are comparing over time and a lot of words. One thing to note about the AFINN lexicon is many of the words that are ranked the most negative (-5) are words that have profanities or are extremely offensive. Although some of these words are featured as quotes in articles we pulled, we decided against including them in our visualizations, filtering them out when needed.\n\n\n\nWe also used a stop_words library in our data analysis. The stop_words library removed common words like “if”, “but”, “we”, “of”, and “they”. Firstly, removing these words do not change the over all semantics of the text one is analyzing and secondly, doing this can sometimes improve the performance of the model. We also created our own list of stop words, which we included names of candidates and other common words not removed from the stop_words library (like “here’s”, “it’s”, and “jr”) because they are common words that would affect our sentiment analysis but removed would not affect the overall meaning.\n\n\n\nWe also utilized a stemming algorithm (Porter’s Algorithm) to reduce the number of words we are analyzing without minimizing the analysis. With the SnowballC package, we can reduce the words to their base or root form. For example, “ran” and “running” would just be reduced to the stem “run”. This streamlines the process of sentiment analysis."
  },
  {
    "objectID": "posts/Sentiment Analysis/index.html#new-york-times",
    "href": "posts/Sentiment Analysis/index.html#new-york-times",
    "title": "The 2020 Presidential Election",
    "section": "New York Times",
    "text": "New York Times\n\nBiden New York Times\nNow that we have the data sets, we can take a look at the trends. First we will construct a time series graph, where we calculate the day score for the articles over one day. Not the green line is U.S. Election Day 2020 or November 4th, 2020.\n\n\n\n\n\nAs we can see from this graph, the sentiment score for Biden trends negative, with it beginning positively as the beginning of 2020 and then decreasing throughout the year, but remaining pretty consistent throughout the rest of the timeline. There isn’t much of a shift after the election (indicated by the green line), or even after January 6th or the inauguration on January 20th, 2021.\nAlthough this graph shows trends, it is worth taking a look at the specific days where there are the highest peaks and lowest dips. What was going on those days?\n\n\n# A tibble: 15 × 2\n   date       day_score\n   <date>         <dbl>\n 1 2020-02-23     0.845\n 2 2020-02-22     0.754\n 3 2020-12-25     0.737\n 4 2020-03-08     0.675\n 5 2020-03-04     0.655\n 6 2020-02-12     0.654\n 7 2020-01-11     0.632\n 8 2020-01-06     0.629\n 9 2020-02-16     0.598\n10 2020-02-19     0.591\n11 2020-03-03     0.581\n12 2020-02-11     0.568\n13 2020-11-04     0.535\n14 2020-03-02     0.516\n15 2020-03-01     0.509\n\n\nLet’s look at what was going on a few of the days that recieved the highest day score:\nFebruary 23rd and 22nd 2020 were the days during this time period where articles were most positive about Joe Biden. Although there doesn’t seem to be a specific event to indicate why, Bernie Sanders, another Democratic challenger in the primary had won Nevada and Biden had just given a positively received interview on Face the Nation, a news program.\nDecember 25th, 2020 is Christmas 2020. This could just indicate positive emotions because of a holiday.\nMarch 8th, 2020 is the day now Vice President Kamala Harris endorsed Joe Biden for President of the United States\nNow, lets look at the days that recieved the worst scores for Joe Biden\n\n\n# A tibble: 1 × 2\n  date       day_score\n  <date>         <dbl>\n1 2020-06-07     -1.08\n\n\nOnly one day received a day score below negative one. One June 2nd, during the height of the civil unrest in the U.S. Biden gave a speech that called for the end to the violence. On the 6th of June, CNN had projected that he secured enough delegates for the Democratic nomination for president.\nTo break this down further, it is worth looking at the percentage of positive and negative articles for Joe Biden, both overall and by month\n\n\n# A tibble: 2 × 4\n  isPositive     n totalArt percent\n  <lgl>      <int>    <int>   <dbl>\n1 FALSE      10253    17343   0.591\n2 TRUE        7090    17343   0.409\n\n\nOverall, 7,090 articles or 40% of the articles for Joe Biden were ruled positive. 10,253 or 59% were ruled negative.\n\n\n\n\n\nHere is a graph that shows the percentage breakdown by month, with 2020 at the bottom and 2022 at the top. We can more clearly see where there are more negative articles than positive and how that can dynamically change over months.\n\n\nTrump New York Times\nNow that we have looked at the trends regarding Joe Biden, let’s do the same for Donald Trump\n\n\n\n\n\nIf we look at the overall trends of the graph, we can clearly see that besides a couple peaks in the graph, more or less the trend for sentiments for Trump articles is negative. Interestingly, there seems to be more variance as well as more positive days for Trump after the election (indicated by the green line). It’s a bit difficult to pinpoint the reason why but we can see that regardless of the broader variance post election, the general trend for the sentiment is overwhelmingly negative.\nAlthough this graph shows trends, it is worth taking a look at the specific days where there are the highest peaks and lowest dips. What was going on those days?\n\n\n# A tibble: 7 × 2\n  date       day_score\n  <date>         <dbl>\n1 2021-11-07     1.11 \n2 2020-12-25     1.10 \n3 2021-10-31     0.995\n4 2021-07-10     0.857\n5 2021-06-10     0.647\n6 2021-05-26     0.547\n7 2021-03-09     0.505\n\n\nAs we can see, there are only a few positive days. Let’s look at the events that were going on around the top three scoring dates\nNovember 7th, 2021: Post election 2021 where there was discussion in paper about Trump conservatism wins. December 25th, 2020: Christmas in the United States, potentially more positive sentiments because of the holiday. October 31st, 2021: Trump allies are at a confrence about Saudi Arabian Investments.\n\n\n# A tibble: 11 × 2\n   date       day_score\n   <date>         <dbl>\n 1 2021-10-23     -1.44\n 2 2021-10-10     -1.33\n 3 2021-11-17     -1.29\n 4 2021-04-11     -1.27\n 5 2021-11-18     -1.21\n 6 2021-05-30     -1.18\n 7 2021-08-10     -1.16\n 8 2021-12-22     -1.10\n 9 2021-08-27     -1.1 \n10 2020-12-26     -1.06\n11 2021-12-20     -1.04\n\n\nLet’s look at the top three worst scoring days: October 23rd, 2021: No specific events relating to Trump October 10th, 2021: Congressional races ahead of election shed Trump in a negative light. November 17th, 2021: Donald Trump seeks to block the January 6th investigations committee from moving forward.\nNow let’s look at the percentage breakdown by month for Trump:\n\n\n# A tibble: 2 × 4\n  isPositive     n totalArt percent\n  <lgl>      <int>    <int>   <dbl>\n1 FALSE       6923    10162   0.681\n2 TRUE        3239    10162   0.319\n\n\nOut of the 10162 articles with the keyword “trump” from the New York Times, 6,923 or 68% were negative. 3,239 or almost 32% were positive. Let’s break this down by month.\n\n\n\n\n\nNow we can see the trends by month, were some months there are many more negative articles than positive, and other months were it is a bit more balanced. One thing to note, in January 2021 many of the articles are negative, which would show connection between the January 6th insurrection of the nations capital by Trump supporters and the how the New York Times wrote about Trump during the month.\n\n\nNew York Times Conclusions\nHere is both of the time series graphs for Donald Trump and Joe Biden shown earlier put together:\n\n\n\n\n\nIn the New York Times between 2020 and 2022, articles written about Joe Biden were more positive than articles written about Donald Trump. In this time period, 40% of articles with the keyword “biden” were positive, compared to articles with the keyword “trump” at 31%. In general, many more days were negative (with a sentiment score value less than 1) for Trump compared to Biden and interestingly enough, for both candidates, their most positive days were days not during their presidential term. For Biden, this was in early 2020 and for Trump this was in 2021 after he was out of office. Overall, we can conclude that the New York Times fairly negative about both candidates but more positive about Joe Biden than Donald Trump during this time period."
  },
  {
    "objectID": "posts/Sentiment Analysis/index.html#guardian",
    "href": "posts/Sentiment Analysis/index.html#guardian",
    "title": "The 2020 Presidential Election",
    "section": "Guardian",
    "text": "Guardian\n\nBiden Guardian\n\n\n\n\n\nSimilar to the time seriies graph of Biden NYT, the daily sentiment scores for Biden fluctuated greatly (most variance) before election day.\n\n\n# A tibble: 1 × 2\n  date       day_score\n  <date>         <dbl>\n1 2020-02-23     0.877\n\n\nInterestingly, Biden only has 1 day on which his sentiment scores were above 0.5. Let’s explore why this is the case.\n2020-02-23: After checking the articles regarding Biden, it turns out that the Democratic members like Bernie Sanders won the primary elections in several big states but Biden only finsished in 2nd or 3 place. We can say that positive articles that mention Biden do not necessarily speak directly to Biden himself, but may be his Democratic party colleagues.\n\n\n# A tibble: 3 × 2\n  date       day_score\n  <date>         <dbl>\n1 2020-06-01     -1.30\n2 2021-09-11     -1.05\n3 2020-05-31     -1.01\n\n\n2020-06-01: Protests against police brutality spread nationwide and caused a great deal of chaos. It makes sense that our sentiment analysis once again thought the overall negativity of the event was directed at Biden (because his name was mentioned) when it was Trump’s name that was mentioned more regularly throughout the article published on this date.\n\n\n# A tibble: 2 × 4\n  isPositive     n totalArt percent\n  <lgl>      <int>    <int>   <dbl>\n1 FALSE       5160     6944   0.743\n2 TRUE        1784     6944   0.257\n\n\nOverall, 74% of Guardian articles written about Biden are negative, compared to a 26% percent for postives.\n\n\n\n\n\nFrom this graph, it seems like Biden was more likely to be included in positive articles during the last months of the each year (Nov and Dec of 2020 and 2021 for example)\n\n\nTrump Guardian\n\n\n\n\n\nUnlike the same time series graph for the NYT, here the daily sentiment scores for Trump behaved wildly even before and after the election.\n\n\n# A tibble: 1 × 2\n  date       day_score\n  <date>         <dbl>\n1 2021-12-25     0.553\n\n\n2021-12-25: Christmas day. We hypothesized that because of this special occasion event, the negativity towards Trump was minimalized.\n\n\n# A tibble: 2 × 2\n  date       day_score\n  <date>         <dbl>\n1 2021-08-13     -1.02\n2 2020-06-11     -1.00\n\n\n2021-08-13: The majority of the Guardian published on this date was discussing the US decision to pull troops out of Afghanistan and because most of these articles quoted Trump and what he would have done otherwise, sentiment analysis did not catch this and his sentimore score hit rock bottom as a result.\n\n\n# A tibble: 2 × 4\n  isPositive     n totalArt percent\n  <lgl>      <int>    <int>   <dbl>\n1 FALSE       8651    11459   0.755\n2 TRUE        2808    11459   0.245\n\n\nLike the percentages for Biden Guardian, the numbers for Trump are relatively the same (74% negative and 26% positive)\n\n\n\n\n\nBased on this graph, there is an obvious dip for Trump during the months of March and especially April in 2020. Thinking back, it could be due to the months when Covid really took a toll on the US and Trump was criticized for his lack of action in preventing the spread of the virus.\n\n\nGuardian Conclusion\nThere are a great number of blue bars fell under 0.25 for both Biden and Trump of The Guardian, which further strengthens our hypothesis that the international newspaper has stronger negative feelings towards the presidential candidates.\nWith regard to the international newspaper, the percentages are more or less the same for both candidates, with both Trump and Biden scoring a staggering 74% on the negative articles and around 26% on the positive ones. Those numbers tell us that the Guardian has a more unbiased view overall. Equivocally speaking, they hate Trump and Biden almost equally.\nOne outstanding dateis the month of 2022-01 when no single positive articles were written about Trump for NYT. After a few Google searches it was one year after the capitol insurrection, Trump was formally accused of 4 crimes and members of congress agreed he should be barred from holding office ever again."
  },
  {
    "objectID": "posts/Sentiment Analysis/index.html#nyt-and-guardian-together",
    "href": "posts/Sentiment Analysis/index.html#nyt-and-guardian-together",
    "title": "The 2020 Presidential Election",
    "section": "NYT and Guardian together",
    "text": "NYT and Guardian together\n\n\n\n\n\nOverall, the Guardian has lower sentiment scores than the NYT. Moreover, it is worth noting that while the Guardian has a more unbiased opinion, they are more critical of each candidate compared to the NYT. That being said, both newspapers follow very similar trend lines for each of the candidates, showing that although the sentiment is lower for the international source, both papers do score based on event similarly."
  }
]