install.packages("quarto")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(lubridate)
library(urltools)
library(scales)
library(textdata)
library(wordcloud)
library(igraph)
library(ggplot2)
library(tidytext)
library(broom)
library(reshape2)
library(ggraph)
data("stop_words")
mystopwords <- tibble(word = c("trump", "trumps", "trump's","trump’s", "biden", "biden's", "biden’s", "donald", "u.s"))
load("/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/totalarticles.RData")
trump <- totalarticles %>%
unnest(headline) %>%
select(abstract, snippet, lead_paragraph, main, pub_date, section_name)
tidy_trump_main <- trump %>%
unnest_tokens(word, main) %>%
anti_join(stop_words) %>%
anti_join(mystopwords) %>%
count(word, sort = TRUE)
tidy_trump_main %>%
inner_join(get_sentiments("bing")) %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
tidy_trump_main %>%
with(wordcloud(word, n, max.words = 50))
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "“https://content.guardianapis.com/search?q=trump&from-date=20210101&page=1"
req <- fromJSON(paste0(url, key))
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=20210101&page=1"
req <- fromJSON(paste0(url, key))
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=20210101&page=1"
req <- fromJSON(paste0(url, key))
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=20210101&page=1"
req <- fromJSON(paste0(url, key))
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-01-01&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210101') + 0:365
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 0
while(p < 10){
url = paste0(link, '&from-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
dates <- ymd('20210101') + 0:10
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 0
while(p < 10){
url = paste0(link, '&from-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-01-01&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210101') + 0:10
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
# guardian_url <- “https://content.guardianapis.com/search”
# guardian_url <- param_set(guardian_url, “q”, url_encode(“2020 US election”))
# guardian_url <- param_set(guardian_url, “api-key”, url_encode(guardian_key))
# dates <- ymd(‘20200101’) + 0:29
# d <- format(dates,‘%Y-%m-%d’)
# df_guardian <- NULL
# for(i in d){
#   p = 1
#   while(p < 10){
#     URL_Guardian = paste0(guardian_url, ‘&from-date=‘,i, “&from-date=“,i ,‘&page=’,p)
#     req_guardian <- fromJSON(URL_Guardian)
#     articles_guardian <- req_guardian$response$results
#     df_guardian <- bind_rows(df_guardian,articles_guardian)
#     if(isTRUE(nrow(articles_guardian)) && nrow(articles_guardian) != 10){break}
#     else{p = p+1}
#     Sys.sleep(6)
#   }
# }
View(totalarticles)
View(req)
quarto::quarto_render()
quarto::quarto_render()
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
req <- fromJSON(paste0(url, key))
articles <- req$response$docs
req
req$response$results
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210101') + 0:10
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
View(totalarticles)
View(totalarticles)
View(articles)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-01-01&to-date=2021-01-01&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$results
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210101') + 0:10
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
for(i in d){
p = 0
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
p = 1
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(6)
}
}
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
# Sys.sleep(6)
}
}
View(totalarticles)
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(8)
}
}
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(10)
}
}
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(12)
}
}
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(18)
}
}
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-01-01&to-date=2021-01-01&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$results
articles
p
d
i
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
p=2
req <- fromJSON(paste0(url, key))
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- fromJSON(paste0(url, key))
p=3
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
try(fromJSON(paste0(url, key)),silent=TRUE)
?try
p=2
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
req
i=d[1]
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}
Sys.sleep(18)
}
req
class(req)
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
if(class(req) == 'try-error'){ break }else{
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}}
Sys.sleep(6)
}
source("~/Desktop/SPRING 2023/STAT 456/comp465/guardian2021 pull request.R")
library(jsonlite)
library(tidyverse)
library(lubridate)
key <- "&api-key=9f51672b-1066-4b6f-a6ca-4066419d6f96"
url <- "https://content.guardianapis.com/search?q=trump&from-date=2021-01-01&to-date=2021-01-01&page=1"
req <- fromJSON(paste0(url, key))
articles <- req$response$results
link = "https://content.guardianapis.com/search?q=trump"
dates <- ymd('20210101') + 0:365
d <- format(dates,'%Y-%m-%d')
totalarticles <- NULL
for(i in d){
p = 1
while(p < 10){
url = paste0(link, '&from-date=',i ,'&to-date=',i ,'&page=',p)
req <- try(fromJSON(paste0(url, key)),silent=TRUE)
if(class(req) == 'try-error'){ break }else{
articles <- req$response$results
totalarticles <- bind_rows(totalarticles,articles)
if(isTRUE(nrow(articles)) && nrow(articles) != 10){ break }
else{p = p+1}}
Sys.sleep(6)
}
}
# guardian_url <- “https://content.guardianapis.com/search”
# guardian_url <- param_set(guardian_url, “q”, url_encode(“2020 US election”))
# guardian_url <- param_set(guardian_url, “api-key”, url_encode(guardian_key))
# dates <- ymd(‘20200101’) + 0:29
# d <- format(dates,‘%Y-%m-%d’)
# df_guardian <- NULL
# for(i in d){
#   p = 1
#   while(p < 10){
#     URL_Guardian = paste0(guardian_url, ‘&from-date=‘,i, “&from-date=“,i ,‘&page=’,p)
#     req_guardian <- fromJSON(URL_Guardian)
#     articles_guardian <- req_guardian$response$results
#     df_guardian <- bind_rows(df_guardian,articles_guardian)
#     if(isTRUE(nrow(articles_guardian)) && nrow(articles_guardian) != 10){break}
#     else{p = p+1}
#     Sys.sleep(6)
#   }
# }
View(totalarticles)
View(articles)
class(totalarticles$webPublicationDate)
as_date(totalarticles$webPublicationDate)
as_date(totalarticles$webPublicationDate)[2872]
save(totalarticles, "/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/guardian2021.RData", file = "guardian2021.RData")
save(totalarticles, "/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/guardian2021.RData", file = "guardian2021.RData")
save(totalarticles, "/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465/guardian2021.RData", file = "guardian2021.RData")
save(totalarticles, "/Users/yiyangshi/Desktop/SPRING 2023/STAT 456/comp465", file = "guardian2021.RData")
quarto::quarto_render()
quarto::quarto_render()
quarto::quarto_render
quarto::quarto_render()
quarto::quarto_render()
library(prettydoc)
install.packages("prettydoc")
library(prettydoc)
quarto::quarto_render()
quarto::quarto_render()
quarto::quarto_render()
save.image("~/Desktop/SPRING 2023/STAT 456/Project/未命名.RData")
library(tidyverse)
library(dplyr)
library(lubridate)
library(urltools)
library(scales)
library(textdata)
# need to be installed
library(wordcloud)
library(igraph)
library(ggplot2)
library(tidytext)
library(broom)
library(reshape2)
library(rvest)
library(tm)
library(ggraph)
library(SnowballC)
library(widyr)
library(tinytex)
data("stop_words")
mystopwords <- tibble(word = c("trump", "trumps", "trump's","trump’s", "biden", "biden's", "biden’s", "donald", "u.s", "joe", "elizabeth", "warren", "here/'s", "sanders", "joseph", "it/'s", "here's", "jr", "vice", "bernie", "obama", "hampshire", "thursday", "tuesday", "bloomberg", "ms", "gail", "bret", "dr", "buttigieg"))
